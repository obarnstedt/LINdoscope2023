{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was originally written by Pat Gunn, Eftychios Pnevmatikakis, Johannes Friedrich, and Andrea Giovannucci from the CaImAn project:  https://github.com/flatironinstitute/CaImAn/blob/master/demos/notebooks/demo_pipeline_cnmfE.ipynb\n",
    "\n",
    "It was later edited by Oliver Barnstedt for the LINdoscope 2021 course: http://www.lindoscope.com\n",
    "\n",
    "The full CaImAn documentation can be found here: \n",
    "https://caiman.readthedocs.io/en/master/core_functions.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline for microendoscopic data processing in CaImAn using the CNMF-E algorithm\n",
    "This demo presents a complete pipeline for processing microendoscopic data using CaImAn. It includes:\n",
    "- Preprocessing of data acquired with Inscopix miniscopes\n",
    "- Motion Correction using the NoRMCorre algorithm\n",
    "- Source extraction using the CNMF-E algorithm\n",
    "- Deconvolution using the OASIS algorithm\n",
    "\n",
    "Some basic visualization is also included. The demo illustrates how to `params`, `MoctionCorrection` and `cnmf` object for processing 1p microendoscopic data. For more information see the companion CaImAn paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    get_ipython().magic(u'load_ext autoreload')\n",
    "    get_ipython().magic(u'autoreload 2')\n",
    "    get_ipython().magic(u'matplotlib qt')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=RuntimeWarning)\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "logging.basicConfig(format=\n",
    "                          \"%(relativeCreated)12d [%(filename)s:%(funcName)20s():%(lineno)s] [%(process)d] %(message)s\",\n",
    "                    # filename=\"/tmp/caiman.log\",\n",
    "                    level=logging.DEBUG)\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.base.movies import load\n",
    "from caiman.summary_images import local_correlations\n",
    "from caiman.source_extraction import cnmf\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.utils.visualization import inspect_correlation_pnr, nb_inspect_correlation_pnr\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
    "from caiman.base.rois import extractROIsFromPCAICA\n",
    "import cv2\n",
    "import napari\n",
    "\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except:\n",
    "    pass\n",
    "import bokeh.plotting as bpl\n",
    "import holoviews as hv\n",
    "bpl.output_notebook()\n",
    "hv.notebook_extension('bokeh')\n",
    "from interactivecrop.interactivecrop import main as crop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-07-05T05:30:54.854531Z",
     "iopub.status.busy": "2021-07-05T05:30:54.854207Z",
     "iopub.status.idle": "2021-07-05T05:30:54.858620Z",
     "shell.execute_reply": "2021-07-05T05:30:54.857611Z",
     "shell.execute_reply.started": "2021-07-05T05:30:54.854460Z"
    }
   },
   "source": [
    "### Preprocess video files\n",
    "The miniscope software saves the raw calcium imaging videos as several large TIFFs. These should be cropped, spatially downsampled, and then concatenated before they can be processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Enter file directory\n",
    "filedir = '/Users/Oliver/LINdoscope2021_files/1P_invitro'\n",
    "\n",
    "# Create 'preprocessed' subfolder\n",
    "new_dir = os.path.join(filedir, 'preprocessed')\n",
    "if not os.path.exists(new_dir):\n",
    "    os.makedirs(new_dir)\n",
    "\n",
    "samplesize = 300  # how many frames to load as sample\n",
    "\n",
    "fnames_raw = sorted(glob.glob(os.path.join(filedir, '*.avi*')))  # finds all TIFF files in filedir folder\n",
    "print(fnames_raw)\n",
    "sample = load(fnames_raw[0], subindices=(range(samplesize)))  # load first couple of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCISE: print dimensions of video sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# EXERCISE: Use Matplotlib's IMSHOW function to plot the first frame. How many cells can you see by eye?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use CaImAn's local_correlations function to create a correlation image\n",
    "cn = local_correlations(sample.transpose(1,2,0))  # needs to be transposed to XYT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# to facilitate processing, we can use the correlation image to crop out XY parts of the video without cells\n",
    "cn_lut = cv2.applyColorMap(np.uint8(cn*255), cv2.COLORMAP_RAINBOW)  # convert correlation image to RGB\n",
    "crop([cn_lut])  # interactive cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# confirm cropping\n",
    "cropping = (60, 0, 647, 480)  # manually copy from interactive cropping results above!  #Inscopix sample: (97, 0, 982, 800)\n",
    "cropped_cn = cn[cropping[1]:cropping[1]+cropping[3],cropping[0]:cropping[0]+cropping[2]]\n",
    "plt.imshow(cropped_cn);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CROP AND DOWNSAMPLE RAW VIDEO (TAKES SOME TIME)\n",
    "sds_ratio = .5  # spatial downsampling  #Isx: .25\n",
    "tds_ratio = .5  # temporal downsampling\n",
    "\n",
    "fnames = [os.path.join(new_dir, os.path.basename(f)[:-4]+'_ds.tif') for f in fnames_raw]  # downsampled file names\n",
    "\n",
    "for i, moviepath in tqdm(enumerate(fnames_raw)):\n",
    "    movie = cm.load(moviepath)\n",
    "\n",
    "    # CROP\n",
    "    movie_cropped = movie[:, cropping[1]:cropping[1]+cropping[3],cropping[0]:cropping[0]+cropping[2]]\n",
    "\n",
    "    # RESIZE\n",
    "    movie_resized = movie_cropped.resize(sds_ratio, sds_ratio, tds_ratio)  # resizing\n",
    "    movie_resized.save(fnames[i])\n",
    "\n",
    "    # CONCATENATE if several files exist\n",
    "    if i==0:\n",
    "        movies_concat = movie_resized.copy()\n",
    "    else:\n",
    "        movies_concat = cm.concatenate([movies_concat, movie_resized], axis=0)\n",
    "    del movie, movie_cropped, movie_resized  # delete objects to save memory\n",
    "\n",
    "# save (concatenated) movie\n",
    "if 'movies_concat' in locals() and i>0:\n",
    "    fname = os.path.join(new_dir, os.path.basename(moviepath)[:-4]+'_concatenated.tif')\n",
    "    if not os.path.exists(fname):\n",
    "        movies_concat.save(fname)\n",
    "else:\n",
    "    fname = fnames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if already downsampled in FIJI:\n",
    "fname = '/Users/Oliver/LINdoscope2021_files/1P_invitro/preprocessed/Untitled_3_MMStack_Default.tif'\n",
    "fnames = ['/Users/Oliver/LINdoscope2021_files/1P_invitro/preprocessed/Untitled_3_MMStack_Default_ds.tif']\n",
    "movies_concat = cm.load(fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save as memmap\n",
    "bord_px = 0\n",
    "fname_new = cm.save_memmap(fnames, base_name='memmap_', order='C', border_to_0=bord_px)\n",
    "\n",
    "# load memory mappable file\n",
    "Yr, dims, T = cm.load_memmap(fname_new)\n",
    "motion_corrected = Yr.T.reshape((T,) + dims, order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# inspect (first) downsampled file\n",
    "if 'movies_concat' not in locals():\n",
    "    movies_concat = cm.load(fname)\n",
    "viewer = napari.view_image(movies_concat, colormap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-08-13T08:29:57.365926Z",
     "iopub.status.busy": "2021-08-13T08:29:57.365466Z",
     "iopub.status.idle": "2021-08-13T08:29:57.889291Z",
     "shell.execute_reply": "2021-08-13T08:29:57.888623Z",
     "shell.execute_reply.started": "2021-08-13T08:29:57.365901Z"
    }
   },
   "source": [
    "### Visualise spatial filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gSig_filt = (3, 3)       # size of high pass spatial filtering, used in 1p data  #Isx(2,2)\n",
    "ksize = tuple([(3 * i) // 2 * 2 + 1 for i in gSig_filt])\n",
    "ker = cv2.getGaussianKernel(ksize[0], gSig_filt[0])\n",
    "ker2D = ker.dot(ker.T)\n",
    "nz = np.nonzero(ker2D >= ker2D[:, 0].max())\n",
    "zz = np.nonzero(ker2D < ker2D[:, 0].max())\n",
    "ker2D[nz] -= ker2D[nz].mean()\n",
    "ker2D[zz] = 0\n",
    "movies_hpfilt = cm.movie(np.array([cv2.filter2D(np.array(img, dtype=np.float32), -1, ker2D, borderType=cv2.BORDER_REFLECT) for img in movies_concat]))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# normalise filtered video and view side-by-side in NAPARI\n",
    "movies_hpfilt_norm = movies_hpfilt + float(np.min(movies_hpfilt))\n",
    "scale_factor = float(np.max(movies_concat)-np.min(movies_concat)) / float(np.max(movies_hpfilt)-np.min(movies_hpfilt))\n",
    "movies_hpfilt_norm = movies_hpfilt_norm * scale_factor + float(np.min(movies_concat))\n",
    "view_spatial_filtering = np.concatenate([movies_concat, movies_hpfilt_norm], 2)\n",
    "viewer = napari.view_image(view_spatial_filtering, colormap='viridis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save video\n",
    "movies_hpfilt_norm.save(fname[:-4]+'_hpfilt.tif')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup a cluster\n",
    "To enable parallel processing a (local) cluster needs to be set up. This is done with a cell below. The variable `backend` determines the type of cluster used. The default value `'local'` uses the multiprocessing package. The `ipyparallel` option is also available. More information on these choices can be found [here](https://github.com/flatironinstitute/CaImAn/blob/master/CLUSTER.md). The resulting variable `dview` expresses the cluster option. If you use `dview=dview` in the downstream analysis then parallel processing will be used. If you use `dview=None` then no parallel processing will be employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup some parameters\n",
    "We first set some parameters related to the data and motion correction and create a `params` object. We'll modify this object with additional settings later on. You can also set all the parameters at once as demonstrated in the `demo_pipeline.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset dependent parameters\n",
    "frate = 10                      # movie frame rate\n",
    "decay_time = 0.8                 # length of a typical transient in seconds; optimal for GCaMP6f (fast) 0.3\n",
    "\n",
    "# motion correction parameters\n",
    "motion_correct = True    # flag for performing motion correction\n",
    "pw_rigid = False         # flag for performing piecewise-rigid motion correction (otherwise just rigid)\n",
    "gSig_filt = (3, 3)       # size of high pass spatial filtering, used in 1p data\n",
    "max_shifts = (20, 20)    # maximum allowed rigid shift\n",
    "border_nan = 'copy'      # replicate values along the boundaries\n",
    "\n",
    "mc_dict = {\n",
    "    'fnames': fnames,\n",
    "    'fr': frate,\n",
    "    'decay_time': decay_time,\n",
    "    'pw_rigid': pw_rigid,\n",
    "    'max_shifts': max_shifts,\n",
    "    'gSig_filt': gSig_filt,\n",
    "    'border_nan': border_nan\n",
    "}\n",
    "\n",
    "opts = params.CNMFParams(params_dict=mc_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MOTION CORRECTION (takes some time)\n",
    "mc = MotionCorrect(fname, dview=dview, **opts.get_group('motion'))\n",
    "mc.motion_correct(save_movie=True)  # motion corrects and saves memory mapped file in order 'F'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "bord_px = np.ceil(np.max(np.abs(mc.shifts_rig))).astype(np.int)\n",
    "plt.subplot(1, 2, 1); plt.imshow(mc.total_template_rig)  # % plot template\n",
    "plt.subplot(1, 2, 2); plt.plot(mc.shifts_rig)  # % plot rigid shifts\n",
    "plt.legend(['x shifts', 'y shifts'])\n",
    "plt.xlabel('frames')\n",
    "plt.ylabel('pixels')\n",
    "\n",
    "# saving memory mapped file in order 'C'\n",
    "bord_px = 0 if border_nan is 'copy' else bord_px\n",
    "fname_mc = mc.fname_tot_rig\n",
    "fname_new = cm.save_memmap(fname_mc, base_name='memmap_', order='C', border_to_0=bord_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove movies from workspace to save memory\n",
    "del movies_concat, movies_hpfilt_norm, movies_hpfilt_mc, vis_mc_nofilter, vis_mc_filtered, vis_mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display motion correction\n",
    "fname_mc = mc.fname_tot_rig\n",
    "bord_px = np.ceil(np.max(np.abs(mc.shifts_rig))).astype(np.int)\n",
    "plt.subplot(1, 2, 1); plt.imshow(mc.total_template_rig)  # % plot template\n",
    "plt.subplot(1, 2, 2); plt.plot(mc.shifts_rig)  # % plot rigid shifts\n",
    "plt.legend(['x shifts', 'y shifts'])\n",
    "plt.xlabel('frames')\n",
    "plt.ylabel('pixels')\n",
    "\n",
    "bord_px = 0 if border_nan is 'copy' else bord_px\n",
    "fname_new = cm.save_memmap(fname_mc, base_name='memmap_', order='C',\n",
    "                           border_to_0=bord_px)\n",
    "\n",
    "# load memory mappable file\n",
    "Yr, dims, T = cm.load_memmap(fname_new)\n",
    "motion_corrected = Yr.T.reshape((T,) + dims, order='F')\n",
    "\n",
    "# apply motion correction to filtered movie\n",
    "movies_hpfilt_mc = mc.apply_shifts_movie(fname[:-4]+'_hpfilt.tif')  # apply motion correction to filtered video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pca_ica(fnames):\n",
    "    m = cm.load(fnames)\n",
    "    \n",
    "    # run pca-ica\n",
    "    output, _ = m.IPCA_stICA(componentsICA=15, mu=0.05)\n",
    "    masks = output.copy()\n",
    "    masks = np.array(extractROIsFromPCAICA(masks)[0])\n",
    "    masks = masks / np.linalg.norm(masks, ord='fro', axis=(1,2))[:, np.newaxis, np.newaxis]\n",
    "    spatial = masks.copy()\n",
    "    \n",
    "    plt.imshow(spatial.sum(0));plt.show()\n",
    "\n",
    "    # from masks recover signal\n",
    "    temporal = m.extract_traces_from_masks(masks)\n",
    "    temporal = -signal_filter(temporal.T, freq=15, fr=400).T\n",
    "    \n",
    "    result = {'spatial':spatial, 'temporal':temporal}\n",
    "    save_path = os.path.join(os.path.split(fnames)[0], 'pca-ica', f'pca-ica_{os.path.split(fnames)[1][:-5]}')\n",
    "    np.save(save_path, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter setting for CNMF-E\n",
    "We now define some parameters for the source extraction step using the CNMF-E algorithm. \n",
    "We construct a new dictionary and use this to modify the *existing* `params` object,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parameters for source extraction and deconvolution\n",
    "p = 1               # order of the autoregressive system\n",
    "K = 200            # upper bound on number of components per patch, in general None  # 100\n",
    "gSig = (3, 3)       # gaussian width of a 2D gaussian kernel, which approximates a neuron  #(3,3)\n",
    "gSiz = None     # average diameter of a neuron, in general 4*gSig+1\n",
    "Ain = None          # possibility to seed with predetermined binary masks\n",
    "merge_thr = .5      # merging threshold, max correlation allowed\n",
    "rf = 40             # half-size of the patches in pixels. e.g., if rf=40, patches are 80x80\n",
    "stride_cnmf = 20    # amount of overlap between the patches in pixels\n",
    "#                     (keep it at least as large as gSiz, i.e 4 times the neuron size gSig)\n",
    "tsub = 2            # downsampling factor in time for initialization,\n",
    "#                     increase if you have memory problems\n",
    "ssub = 1            # downsampling factor in space for initialization,\n",
    "#                     increase if you have memory problems\n",
    "#                     you can pass them here as boolean vectors\n",
    "low_rank_background = None  # None leaves background of each patch intact,\n",
    "#                     True performs global low-rank approximation if gnb>0\n",
    "gnb = 0             # number of background components (rank) if positive,\n",
    "#                     else exact ring model with following settings\n",
    "#                         gnb= 0: Return background as b and W\n",
    "#                         gnb=-1: Return full rank background B\n",
    "#                         gnb<-1: Don't return background\n",
    "nb_patch = 0        # number of background components (rank) per patch if gnb>0,\n",
    "#                     else it is set automatically\n",
    "min_corr = .8       # min peak value from correlation image\n",
    "min_pnr = 10        # min peak to noise ratio from PNR image\n",
    "ssub_B = 2          # additional downsampling factor in space for background\n",
    "ring_size_factor = 1.4  # radius of ring is gSiz*ring_size_factor\n",
    "\n",
    "opts.change_params(params_dict={'method_init': 'corr_pnr',  # use this for 1 photon\n",
    "                                'K': K,\n",
    "                                'gSig': gSig,\n",
    "                                'gSiz': gSiz,\n",
    "                                'merge_thr': merge_thr,\n",
    "                                'p': p,\n",
    "                                'tsub': tsub,\n",
    "                                'ssub': ssub,\n",
    "                                'rf': rf,\n",
    "                                'stride': stride_cnmf,\n",
    "                                'only_init': True,    # set it to True to run CNMF-E\n",
    "                                'nb': gnb,\n",
    "                                'nb_patch': nb_patch,\n",
    "                                'method_deconvolution': 'oasis',       # could use 'cvxpy' alternatively\n",
    "                                'low_rank_background': low_rank_background,\n",
    "                                'update_background_components': True,  # sometimes setting to False improve the results\n",
    "                                'min_corr': min_corr,\n",
    "                                'min_pnr': min_pnr,\n",
    "                                'normalize_init': False,               # just leave as is\n",
    "                                'center_psf': True,                    # leave as is for 1 photon\n",
    "                                'ssub_B': ssub_B,\n",
    "                                'ring_size_factor': ring_size_factor,\n",
    "                                'del_duplicates': True,                # whether to remove duplicates from initialization\n",
    "                                'border_pix': None})                # number of pixels to not consider in the borders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect summary images and set parameters\n",
    "Check the optimal values of `min_corr` and `min_pnr` by moving slider in the figure that pops up. You can modify them in the `params` object. \n",
    "Note that computing the correlation pnr image can be computationally and memory demanding for large datasets. In this case you can compute\n",
    "only on a subset of the data (the results will not change). You can do that by changing `images[::1]` to `images[::5]` or something similar.\n",
    "This will compute the correlation pnr image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute some summary images (correlation and peak to noise)\n",
    "cn_filter, pnr = cm.summary_images.correlation_pnr(motion_corrected[::1], gSig=gSig[0], swap_dim=False) # change swap dim if output looks weird, it is a problem with tiffile\n",
    "# inspect the summary images and set the parameters\n",
    "nb_inspect_correlation_pnr(cn_filter, pnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the correlation and PNR images to select the threshold values for `min_corr` and `min_pnr`. The algorithm will look for components only in places where these value are above the specified thresholds. You can adjust the dynamic range in the plots shown above by choosing the selection tool (third button from the left) and selecting the desired region in the histogram plots on the right of each panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print parameters set above, modify them if necessary based on summary images\n",
    "print(min_corr) # min correlation of peak (from correlation image)\n",
    "print(min_pnr)  # min peak to noise ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the CNMF-E algorithm (takes some time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(motion_corrected[500,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnm = cnmf.CNMF(n_processes=n_processes, dview=dview, Ain=Ain, params=opts)\n",
    "cnm.fit(motion_corrected)\n",
    "cnm.save(fnames[0][:-4]+'_cnm.hdf5')  # save file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component Evaluation\n",
    "\n",
    "The processing in patches creates several spurious components. These are filtered out by evaluating each component using three different criteria:\n",
    "\n",
    "- the shape of each component must be correlated with the data at the corresponding location within the FOV\n",
    "- a minimum peak SNR is required over the length of a transient\n",
    "\n",
    "After setting some parameters we again modify the existing `params` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%% COMPONENT EVALUATION\n",
    "# the components are evaluated in three ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient\n",
    "#   c) each shape passes a CNN based classifier\n",
    "\n",
    "min_SNR = 5            # adaptive way to set threshold on the transient size\n",
    "r_values_min = 0.2    # threshold on space consistency (if you lower more components\n",
    "#                        will be accepted, potentially with worse quality)\n",
    "cnm.params.set('quality', {'min_SNR': min_SNR,\n",
    "                           'rval_thr': r_values_min,\n",
    "                           'use_cnn': False})\n",
    "cnm.estimates.evaluate_components(motion_corrected, cnm.params, dview=dview)\n",
    "\n",
    "print(' ***** ')\n",
    "print('Number of total components: ', len(cnm.estimates.C))\n",
    "print('Number of accepted components: ', len(cnm.estimates.idx_components))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sum(cnm.estimates.SNR_comp<5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cnm.estimates.r_values>0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do some plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%% plot contour plots of accepted and rejected components\n",
    "cnm.estimates.plot_contours_nb(img=cn_filter, idx=cnm.estimates.idx_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View traces of accepted and rejected components. Note that if you get data rate error you can start Jupyter notebooks using:\n",
    "'jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accepted components\n",
    "cnm.estimates.hv_view_components(img=cn_filter, idx=cnm.estimates.idx_components,\n",
    "                                denoised_color='red', cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejected components\n",
    "cnm.estimates.hv_view_components(img=cn_filter, idx=cnm.estimates.idx_components_bad,\n",
    "                                denoised_color='red', cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.stop_server(dview=dview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some instructive movies\n",
    "Play the reconstructed movie alongside the original movie and the (amplified) residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with background \n",
    "cnm.estimates.play_movie(motion_corrected, q_max=99.5, magnification=2, include_bck=True, gain_res=10, bpx=bord_px);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without background\n",
    "cnm.estimates.play_movie(motion_corrected, q_max=99.9, magnification=2, include_bck=False, gain_res=4, bpx=bord_px);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
